{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#***IRIS FLOWER FEATURE EXTRACTION MODEL***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##***DataSet Collection***\n",
    "\n",
    "https://www.kaggle.com/datasets/irijabbutt/iris-flower-plot-image-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##***LOAD DATA***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Load the dataset\n",
    "train_dir = 'D:/Rijab/.vscode/Repos/Machine-Learning-Projects/dataset/iris_png/train'\n",
    "test_dir = 'D:/Rijab/.vscode/Repos/Machine-Learning-Projects/dataset/iris_png/test'\n",
    "train_images = []\n",
    "train_labels = []\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for class_dir in os.listdir(train_dir):\n",
    "    class_dir_path = os.path.join(train_dir, class_dir)\n",
    "    for filename in os.listdir(class_dir_path):\n",
    "        filepath = os.path.join(class_dir_path, filename)\n",
    "        img = plt.imread(filepath)\n",
    "        img = img / 255.0\n",
    "        label = class_dir\n",
    "    train_images.append(img)\n",
    "    train_labels.append(label)\n",
    "\n",
    "for class_dir in os.listdir(test_dir):\n",
    "    class_dir_path = os.path.join(test_dir, class_dir)\n",
    "    for filename in os.listdir(class_dir_path):\n",
    "        filepath = os.path.join(class_dir_path, filename)\n",
    "        img = plt.imread(filepath)\n",
    "        img = img / 255.0\n",
    "        label = class_dir\n",
    "    test_images.append(img)\n",
    "    test_labels.append(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: (3, 480, 640, 4)\n",
      "Test Images: (3, 480, 640, 4)\n",
      "Train Labels: (3,)\n",
      "Test Labels: (3,)\n"
     ]
    }
   ],
   "source": [
    "train_img=np.array(train_images)\n",
    "test_img=np.array(test_images)\n",
    "train_lab=np.array(train_labels)\n",
    "test_lab=np.array(test_labels)\n",
    "print('Train Images:',train_img.shape)\n",
    "print('Test Images:',test_img.shape)\n",
    "print('Train Labels:',train_lab.shape)\n",
    "print('Test Labels:',test_lab.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##***DATA PREPROCESSING***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_img, test_img, train_lab, test_lab\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Convert to grayscale\n",
    "x_train_gray = np.dot(x_train[...,:3], [0.299, 0.587, 0.114])\n",
    "x_test_gray = np.dot(x_test[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "# Reshape to 2D arrays\n",
    "x_train_gray = x_train_gray.reshape(x_train_gray.shape[0], -1)\n",
    "x_test_gray = x_test_gray.reshape(x_test_gray.shape[0], -1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert string labels to numerical labels\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##***CNN MODEL ARCHITECTURE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "class Conv2D:\n",
    "    \n",
    "    def __init__(self, kernel_size, filters, activation, channels, input_shape):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.filters = filters\n",
    "        self.activation = activation\n",
    "        self.channels = channels\n",
    "        self.input_shape = input_shape\n",
    "        self.weights = np.random.rand(self.kernel_size[0], self.kernel_size[1], 4, 3)\n",
    "        self.bias = np.zeros((filters,))\n",
    "\n",
    "    def forward(self, input):\n",
    "        if len(input.shape) == 3:\n",
    "            input = input.reshape(input.shape[0], input.shape[1], input.shape[2], 1)\n",
    "        output = np.zeros((input.shape[0], input.shape[1] - self.kernel_size[0] + 1, input.shape[2] - self.kernel_size[1] + 1, self.filters))\n",
    "\n",
    "        for j in range(input.shape[1] - self.kernel_size[0] + 1):\n",
    "            for k in range(input.shape[2] - self.kernel_size[1] + 1):\n",
    "                for i in range(self.filters):\n",
    "                    for m in range(self.kernel_size[0]):\n",
    "                        for n in range(self.kernel_size[1]):\n",
    "                            if 0 <= j + m < input.shape[1] and 0 <= k + n < input.shape[2]:\n",
    "                                k_n = min(k + n, input.shape[2] - 1)\n",
    "                                j_m = min(j + m, input.shape[1] - 1)\n",
    "                                k_idx = np.clip(k, 0, output.shape[2] - 1)\n",
    "                                output[:, j_m, k_idx, i] += np.dot(input[:, j_m, k_n, 0].reshape(-1, 1), self.weights[m, n, i, :].reshape(1, -1))[0, 0]\n",
    "                    output[:, j, k_idx, i] += self.bias[i]\n",
    "        return output\n",
    "\n",
    "    def backward(self, input, error):\n",
    "        self.weights_grad = np.zeros_like(self.weights)\n",
    "        self.bias_grad = np.zeros_like(self.bias)\n",
    "        for i in range(self.filters):\n",
    "            for j in range(error.shape[0]):\n",
    "                for k in range(error.shape[1]):\n",
    "                    self.weights_grad[:, :, :, i] += np.sum(input[j:j+self.kernel_size, k:k+self.kernel_size, :] * error[j, k, i], axis=2)\n",
    "                    self.bias_grad[i] += error[j, k, i]\n",
    "        return error\n",
    "\n",
    "class MaxPool2D:\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "\n",
    "    def forward(self, input):\n",
    "        output_shape = ((input.shape[0] + self.pool_size - 1) // self.pool_size, \n",
    "                        (input.shape[1] + self.pool_size - 1) // self.pool_size, \n",
    "                        input.shape[2])\n",
    "        output = np.zeros(output_shape)\n",
    "        for i in range(input.shape[2]):\n",
    "            for j in range(0, input.shape[0], self.pool_size):\n",
    "                for k in range(0, input.shape[1], self.pool_size):\n",
    "                    output[j // self.pool_size, k // self.pool_size, i] = np.max(input[j:j+self.pool_size, k:k+self.pool_size, i])\n",
    "        return output\n",
    "\n",
    "class Flatten:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input.reshape(input.shape[0], -1)\n",
    "\n",
    "    def backward(self, error):\n",
    "        return error.reshape(error.shape[0], -1)\n",
    "\n",
    "class Dense:\n",
    "    def __init__(self, num_inputs, units):\n",
    "        self.units = units\n",
    "        self.weights = np.random.rand(num_inputs, units)\n",
    "        self.bias = np.zeros((units,))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return np.dot(input, self.weights) + self.bias\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = input\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(output)\n",
    "        return output\n",
    "\n",
    "    def compile(self, optimizer, loss, metrics):\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "\n",
    "    def fit(self, x_train, y_train, batch_size, epochs, validation_data, callbacks):\n",
    "        history = {\"epochs\": [],\"loss\": [], \"accuracy\": []}\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(0, len(x_train), batch_size):\n",
    "                x_batch = x_train[i:i+batch_size]\n",
    "                y_batch = y_train[i:i+batch_size]\n",
    "                output = self.forward(x_batch)\n",
    "                error = self.loss(y_batch, output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward(error)\n",
    "                self.optimizer.update(self.layers)\n",
    "            history[\"epochs\"].append(epoch)\n",
    "            history[\"loss\"].append(error)\n",
    "            history[\"accuracy\"].append(self.metrics(y_train, self.forward(x_train)))\n",
    "            \n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "x_gray = np.concatenate((train_img, test_img), axis=0)\n",
    "y = np.concatenate((train_lab, test_lab), axis=0)\n",
    "\n",
    "x_train_gray, x_test_gray, y_train, y_test = train_test_split(\n",
    "    x_gray, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "validation_data = (x_test_gray, y_test)\n",
    "callbacks = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network\n",
    "nn = NeuralNetwork()\n",
    "input = np.random.rand(32, 32, 3)\n",
    "ch=3\n",
    "# Define the model architecture\n",
    "layers = []\n",
    "layers.append(Conv2D(kernel_size=(3, 3), filters=8, activation='relu', channels=ch, input_shape=input))\n",
    "layers.append(MaxPool2D(2))\n",
    "layers.append(Conv2D(kernel_size=(3, 3), filters=8, activation='relu', channels=ch, input_shape=input))\n",
    "layers.append(MaxPool2D(2))\n",
    "layers.append(Conv2D(kernel_size=(3, 3), filters=8, activation='relu', channels=ch, input_shape=input))\n",
    "layers.append(MaxPool2D(2))\n",
    "layers.append(Flatten())\n",
    "conv_output_shape = layers[-1].forward(np.zeros((1, 32, 32, 1))).shape\n",
    "layers.append(Dense(num_inputs=conv_output_shape[0], units=3))\n",
    "\n",
    "# Add the layers to the neural network\n",
    "for layer in layers:\n",
    "    nn.add_layer(layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 2 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseCategoricalCrossentropy\n\u001b[0;32m      4\u001b[0m nn\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m), loss\u001b[38;5;241m=\u001b[39mSparseCategoricalCrossentropy(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs:\u001b[39m\u001b[38;5;124m\"\u001b[39m,history,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, history, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, history)\n",
      "Cell \u001b[1;32mIn[5], line 100\u001b[0m, in \u001b[0;36mNeuralNetwork.fit\u001b[1;34m(self, x_train, y_train, batch_size, epochs, validation_data, callbacks)\u001b[0m\n\u001b[0;32m     98\u001b[0m x_batch \u001b[38;5;241m=\u001b[39m x_train[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m     99\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_train[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m--> 100\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(y_batch, output)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n",
      "Cell \u001b[1;32mIn[5], line 86\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     84\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 86\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "Cell \u001b[1;32mIn[5], line 28\u001b[0m, in \u001b[0;36mConv2D.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     26\u001b[0m                         j_m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(j \u001b[38;5;241m+\u001b[39m m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     27\u001b[0m                         k_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(k, \u001b[38;5;241m0\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m                         output[:, j_m, k_idx, i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28minput\u001b[39m[:, j_m, k_n, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     29\u001b[0m             output[:, j, k_idx, i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias[i]\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mIndexError\u001b[0m: index 4 is out of bounds for axis 2 with size 4"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "nn.compile(optimizer=Adam(learning_rate=0.01), loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "history = nn.fit(x_train_gray, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test_gray,y_test), callbacks=callbacks)\n",
    "\n",
    "print(\"Epochs:\",history,\"Loss:\", history, \"Accuracy:\", history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract features from the input image\n",
    "features = nn.forward(input)\n",
    "\n",
    "# Plot the extracted features\n",
    "plt.imshow(features[0, :, :, 0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 480, 640, 4)\n",
      "(3, 480, 640, 4)\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(layer.weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##***CNN MODEL SUMMARY***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------\n",
      "1. Conv2D:\n",
      "  - Filters: 8\n",
      "  - Kernel Size: (3, 3)\n",
      "2. MaxPool2D:\n",
      "  - Pool Size: 2\n",
      "3. Conv2D:\n",
      "  - Filters: 8\n",
      "  - Kernel Size: (3, 3)\n",
      "4. MaxPool2D:\n",
      "  - Pool Size: 2\n",
      "5. Conv2D:\n",
      "  - Filters: 8\n",
      "  - Kernel Size: (3, 3)\n",
      "6. MaxPool2D:\n",
      "  - Pool Size: 2\n",
      "7. Flatten:\n",
      "8. Dense:\n",
      "  - Units: 3\n"
     ]
    }
   ],
   "source": [
    "def print_model_summary(nn):\n",
    "    print(\"Model Summary:\")\n",
    "    print(\"----------------\")\n",
    "    for i, layer in enumerate(nn):\n",
    "        if isinstance(layer, Conv2D):\n",
    "            print(f\"{i+1}. Conv2D:\")\n",
    "            print(f\"  - Filters: {layer.filters}\")\n",
    "            print(f\"  - Kernel Size: {layer.kernel_size}\")\n",
    "        elif isinstance(layer, MaxPool2D):\n",
    "            print(f\"{i+1}. MaxPool2D:\")\n",
    "            print(f\"  - Pool Size: {layer.pool_size}\")\n",
    "        elif isinstance(layer, Flatten):\n",
    "            print(f\"{i+1}. Flatten:\")\n",
    "        elif isinstance(layer, Dense):\n",
    "            print(f\"{i+1}. Dense:\")\n",
    "            print(f\"  - Units: {layer.units}\")\n",
    "        else:\n",
    "            print(f\"Unknown layer type: {type(layer)}\")\n",
    "\n",
    "print_model_summary(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##***TRAIN & TEST MODEL***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size\n",
    "batch_size = 100\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(10):\n",
    "    for i in range(0, len(train_images), batch_size):\n",
    "        batch_inputs = train_images[i:i+batch_size]\n",
    "        batch_labels = train_labels[i:i+batch_size]\n",
    "        batch_outputs = []\n",
    "        for input in batch_inputs:\n",
    "            output = input\n",
    "            for layer in layers:\n",
    "                output = layer.forward(output)\n",
    "            batch_outputs.append(output)\n",
    "        batch_loss = np.sum((np.array(batch_outputs) - np.array(batch_labels)) ** 2)\n",
    "        print(f'Epoch {epoch+1}, Batch {i//batch_size+1}, Loss: {batch_loss:.4f}')\n",
    "\n",
    "# Test the model\n",
    "test_outputs = []\n",
    "for i in range(0, len(test_images), batch_size):\n",
    "    batch_inputs = test_images[i:i+batch_size]\n",
    "    batch_outputs = []\n",
    "    for input in batch_inputs:\n",
    "        output = input\n",
    "        for layer in layers:\n",
    "            output = layer.forward(output)\n",
    "        batch_outputs.append(output)\n",
    "    test_outputs.extend(batch_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##***PLOTTING RESULTS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy and loss\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##***PERFORMANCE RESULTS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy = 0\n",
    "f1 = 0\n",
    "precision = 0\n",
    "dice_similarity = 0\n",
    "for i in range(len(test_outputs)):\n",
    "     output = test_outputs[i]\n",
    "     label = test_labels[i]\n",
    "     accuracy += np.argmax(output) == label\n",
    "     f1 += 2 * np.sum(output * label) / (np.sum(output) + np.sum(label))\n",
    "     precision += np.sum(output* label) / np.sum(output)\n",
    "     dice_similarity += 2 * np.sum(output * label) / (np.sum(output ** 2) + np.sum(label ** 2))\n",
    "accuracy /= len(test_outputs)\n",
    "f1 /= len(test_outputs)\n",
    "precision /= len(test_outputs)\n",
    "dice_similarity /= len(test_outputs)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Dice Similarity: {dice_similarity:.4f}')\n",
    "\n",
    "# Plot graphs for results\n",
    "plt.plot([i for i in range(len(test_outputs))], [np.argmax(output) for output in test_outputs], label='Predicted')\n",
    "plt.plot([i for i in range(len(test_outputs))], test_labels, label='Ground Truth')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
